# SniperForge Enterprise Infrastructure Configuration
# Phase 5: Advanced Enterprise Optimization

version: '3.8'

services:
  # Main SniperForge Application - Multiple Instances for High Availability
  sniperforge-app-1:
    build:
      context: .
      dockerfile: Dockerfile.enterprise
    image: sniperforge:enterprise-v3.0.0
    container_name: sniperforge-primary
    restart: unless-stopped
    environment:
      - RUST_LOG=info
      - SNIPERFORGE_ENV=production
      - SNIPERFORGE_MODE=enterprise
      - INSTANCE_ID=primary
      - DATABASE_URL=postgresql://sniperforge:${DB_PASSWORD}@postgres:5432/sniperforge_enterprise
      - REDIS_URL=redis://redis-cluster:7000
      - MONITORING_ENABLED=true
      - HFT_ENGINE_ENABLED=true
      - MAX_CONCURRENT_TRADES=1000
      - PERFORMANCE_MODE=maximum
    volumes:
      - ./config/production:/app/config:ro
      - ./logs:/app/logs
      - ./data:/app/data
    ports:
      - "8080:8080"  # API Server
      - "9090:9090"  # Metrics/Monitoring
      - "8081:8081"  # Health Check
    networks:
      - sniperforge-network
    depends_on:
      - postgres
      - redis-cluster
      - prometheus
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '2.0'
          memory: 4G

  # Secondary Instance for Load Balancing
  sniperforge-app-2:
    build:
      context: .
      dockerfile: Dockerfile.enterprise
    image: sniperforge:enterprise-v3.0.0
    container_name: sniperforge-secondary
    restart: unless-stopped
    environment:
      - RUST_LOG=info
      - SNIPERFORGE_ENV=production
      - SNIPERFORGE_MODE=enterprise
      - INSTANCE_ID=secondary
      - DATABASE_URL=postgresql://sniperforge:${DB_PASSWORD}@postgres:5432/sniperforge_enterprise
      - REDIS_URL=redis://redis-cluster:7000
      - MONITORING_ENABLED=true
      - HFT_ENGINE_ENABLED=true
      - MAX_CONCURRENT_TRADES=1000
      - PERFORMANCE_MODE=maximum
    volumes:
      - ./config/production:/app/config:ro
      - ./logs:/app/logs
      - ./data:/app/data
    ports:
      - "8082:8080"  # API Server
      - "9091:9090"  # Metrics/Monitoring
      - "8083:8081"  # Health Check
    networks:
      - sniperforge-network
    depends_on:
      - postgres
      - redis-cluster
      - prometheus
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '2.0'
          memory: 4G

  # Load Balancer - HAProxy for High Availability
  load-balancer:
    image: haproxy:2.8-alpine
    container_name: sniperforge-lb
    restart: unless-stopped
    volumes:
      - ./config/haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    ports:
      - "80:80"     # HTTP Load Balancer
      - "443:443"   # HTTPS Load Balancer
      - "8404:8404" # HAProxy Stats
    networks:
      - sniperforge-network
    depends_on:
      - sniperforge-app-1
      - sniperforge-app-2
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "80"]
      interval: 10s
      timeout: 3s
      retries: 3

  # PostgreSQL Database - Enterprise Configuration
  postgres:
    image: postgres:15-alpine
    container_name: sniperforge-db
    restart: unless-stopped
    environment:
      - POSTGRES_DB=sniperforge_enterprise
      - POSTGRES_USER=sniperforge
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_INITDB_ARGS=--auth-host=scram-sha-256
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./config/postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - ./config/postgres/init:/docker-entrypoint-initdb.d:ro
    ports:
      - "5432:5432"
    networks:
      - sniperforge-network
    command: ["postgres", "-c", "config_file=/etc/postgresql/postgresql.conf"]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U sniperforge -d sniperforge_enterprise"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G

  # Redis Cluster for Caching and Session Management
  redis-cluster:
    image: redis:7-alpine
    container_name: sniperforge-redis
    restart: unless-stopped
    command: redis-server --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --appendonly yes
    volumes:
      - redis_data:/data
      - ./config/redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    ports:
      - "7000:7000"
    networks:
      - sniperforge-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G

  # Prometheus - Metrics Collection
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: sniperforge-prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    volumes:
      - ./config/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./config/prometheus/rules:/etc/prometheus/rules:ro
      - prometheus_data:/prometheus
    ports:
      - "9092:9090"
    networks:
      - sniperforge-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Grafana - Monitoring Dashboard
  grafana:
    image: grafana/grafana:10.1.0
    container_name: sniperforge-grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./config/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./config/grafana/dashboards:/var/lib/grafana/dashboards:ro
    ports:
      - "3000:3000"
    networks:
      - sniperforge-network
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Elasticsearch - Log Aggregation
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.9.0
    container_name: sniperforge-elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - xpack.security.enabled=false
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - sniperforge-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G

  # Kibana - Log Visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:8.9.0
    container_name: sniperforge-kibana
    restart: unless-stopped
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - SERVER_NAME=sniperforge-kibana
    ports:
      - "5601:5601"
    networks:
      - sniperforge-network
    depends_on:
      - elasticsearch
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Logstash - Log Processing
  logstash:
    image: docker.elastic.co/logstash/logstash:8.9.0
    container_name: sniperforge-logstash
    restart: unless-stopped
    volumes:
      - ./config/logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./config/logstash/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./logs:/var/log/sniperforge:ro
    ports:
      - "5044:5044"  # Beats input
      - "5000:5000"  # TCP input
    networks:
      - sniperforge-network
    depends_on:
      - elasticsearch
    environment:
      - "LS_JAVA_OPTS=-Xmx1g -Xms1g"

  # Jaeger - Distributed Tracing
  jaeger:
    image: jaegertracing/all-in-one:1.48
    container_name: sniperforge-jaeger
    restart: unless-stopped
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
    ports:
      - "16686:16686"  # Jaeger UI
      - "14268:14268"  # HTTP collector
      - "14250:14250"  # gRPC collector
      - "9411:9411"    # Zipkin collector
    networks:
      - sniperforge-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:16686/"]
      interval: 30s
      timeout: 10s
      retries: 3

  # NGINX - Reverse Proxy and Static File Serving
  nginx:
    image: nginx:1.25-alpine
    container_name: sniperforge-nginx
    restart: unless-stopped
    volumes:
      - ./config/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./config/nginx/conf.d:/etc/nginx/conf.d:ro
      - ./static:/usr/share/nginx/html:ro
      - ./ssl:/etc/nginx/ssl:ro
    ports:
      - "8443:443"  # HTTPS
      - "8084:80"   # HTTP
    networks:
      - sniperforge-network
    depends_on:
      - load-balancer
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Backup Service
  backup:
    build:
      context: ./docker/backup
    container_name: sniperforge-backup
    restart: unless-stopped
    environment:
      - DB_HOST=postgres
      - DB_NAME=sniperforge_enterprise
      - DB_USER=sniperforge
      - DB_PASSWORD=${DB_PASSWORD}
      - S3_BUCKET=${BACKUP_S3_BUCKET}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - BACKUP_SCHEDULE=0 2 * * *  # Daily at 2 AM
    volumes:
      - ./backups:/backups
      - postgres_data:/var/lib/postgresql/data:ro
    networks:
      - sniperforge-network
    depends_on:
      - postgres

  # Watchtower - Automatic Updates
  watchtower:
    image: containrrr/watchtower:latest
    container_name: sniperforge-watchtower
    restart: unless-stopped
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    command: --schedule "0 0 4 * * *" --cleanup --include-stopped sniperforge
    environment:
      - WATCHTOWER_NOTIFICATIONS=slack
      - WATCHTOWER_NOTIFICATION_SLACK_HOOK_URL=${SLACK_WEBHOOK_URL}

networks:
  sniperforge-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  elasticsearch_data:
    driver: local

# Environment Variables Template
# Copy to .env and fill in the values:
#
# DB_PASSWORD=your_secure_database_password
# GRAFANA_PASSWORD=your_secure_grafana_password
# BACKUP_S3_BUCKET=your-backup-s3-bucket
# AWS_ACCESS_KEY_ID=your_aws_access_key
# AWS_SECRET_ACCESS_KEY=your_aws_secret_key
# SLACK_WEBHOOK_URL=your_slack_webhook_url_for_notifications
